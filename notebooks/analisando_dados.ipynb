{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Pré-processamento de dados de dados\n",
    "\n",
    "Esse código realiza o pré-processamento dos dados de interação do usuário, gerando uma matriz de interação e transformando informações históricas em um formato estruturado.\n",
    "\n",
    "Principais funções\n",
    "\n",
    "✅ calc_recency_score(issued): Calcula a pontuação de recência de notícias, dando mais peso às mais recentes. \\\n",
    "✅ parse_date_timestamp(date): Converte timestamps para milissegundos, garantindo consistência no formato. \\\n",
    "✅ build_interaction_matrix(df, interaction_columns, chunk_size=10000): Constrói uma matriz esparsa de interação usuário-notícia em chunks, útil para grandes volumes de dados. \\\n",
    "✅ transform_user_to_info_user_item(user_info): Transforma os dados brutos do usuário em um formato mais estruturado e pronto para análise."
   ],
   "id": "f48c66334d4227d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "\n",
    "interaction_columns = [\n",
    "    'pageVisitsCountHistory',\n",
    "    'scrollPercentageHistory',\n",
    "]\n",
    "\n",
    "def calc_recency_score(issued: pd.Series):\n",
    "    \"\"\"\n",
    "    Calcula o score de recência para uma série de timestamps.\n",
    "\n",
    "    O score é inversamente proporcional ao tempo decorrido,\n",
    "    dando mais prioridade a notícias mais recentes.\n",
    "\n",
    "    :param issued: Série com os timestamps das notícias.\n",
    "    :return: Série com os scores de recência.\n",
    "    \"\"\"\n",
    "    # Converter os timestamps para milissegundos\n",
    "\n",
    "    now = parse_date_timestamp(datetime.timestamp(datetime.now()))\n",
    "\n",
    "    # Calcular o score de recência, evitando divisão por zero\n",
    "    return 1 / np.maximum(now - parse_date_timestamp(issued), 1e-6)\n",
    "\n",
    "\n",
    "def parse_date_timestamp(date):\n",
    "    # Converte para datetime se ainda for string\n",
    "    if isinstance(date, str):\n",
    "        date = pd.to_datetime(date, errors='coerce')\n",
    "    elif isinstance(date, float):\n",
    "        return (date * 1000)\n",
    "\n",
    "    return int(datetime.timestamp(date) * 1000)\n",
    "\n",
    "\n",
    "def build_interaction_matrix(df, interaction_columns, chunk_size=10000):\n",
    "    \"\"\"\n",
    "    Constrói uma matriz de interação a partir de um DataFrame específico em chunks.\n",
    "    Garante que todas as matrizes parciais tenham as mesmas colunas automaticamente.\n",
    "    Retorna uma matriz esparsa empilhada verticalmente.\n",
    "    \"\"\"\n",
    "    interaction_matrix = []\n",
    "\n",
    "    # Extrai todas as colunas únicas automaticamente do DataFrame\n",
    "    all_columns = df['history'].unique()\n",
    "    print(f\"Colunas únicas encontradas: {len(all_columns)}\")\n",
    "\n",
    "    for start in tqdm(range(0, len(df), chunk_size), desc='Building interaction matrix'):\n",
    "        chunk = df.iloc[start:start + chunk_size]\n",
    "\n",
    "        # Gera a matriz de interação parcial\n",
    "        partial_matrix = chunk.pivot_table(\n",
    "            index='userId',\n",
    "            columns='history',\n",
    "            values=interaction_columns,\n",
    "            aggfunc='mean',\n",
    "            fill_value=0\n",
    "        )\n",
    "\n",
    "        # Reindexa para garantir a consistência das colunas\n",
    "        partial_matrix = partial_matrix.reindex(columns=all_columns, fill_value=0)\n",
    "\n",
    "        # Converte para matriz esparsa e acumula\n",
    "        interaction_matrix.append(csr_matrix(partial_matrix))\n",
    "\n",
    "    # Retorna a matriz esparsa empilhada verticalmente\n",
    "    return vstack(interaction_matrix)\n",
    "\n",
    "\n",
    "def transform_user_to_info_user_item(user_info):\n",
    "    user_item = user_info[['userId', 'history', 'timestampHistory', 'numberOfClicksHistory', 'timeOnPageHistory', 'scrollPercentageHistory', 'pageVisitsCountHistory', 'timestampHistory_new']]\n",
    "\n",
    "    user_item = user_item.set_index('userId').apply(lambda row: row.str.split(','), axis=1)\n",
    "    user_item = user_item.apply(pd.Series.explode).reset_index()\n",
    "    user_item['numberOfClicksHistory'] = user_item['numberOfClicksHistory'].astype(int)\n",
    "    user_item['timeOnPageHistory'] = user_item['timeOnPageHistory'].astype(int)\n",
    "    user_item['scrollPercentageHistory'] = user_item['scrollPercentageHistory'].astype(float)\n",
    "    user_item['timestampHistory'] = pd.to_numeric(user_item['timestampHistory'], errors='coerce').fillna(0).astype(int)\n",
    "    user_item['pageVisitsCountHistory'] = pd.to_numeric(user_item['pageVisitsCountHistory'], errors='coerce').fillna(0).astype(int)\n",
    "    user_item['history'] = user_item['history'].str.strip()\n",
    "    user_item['userId'] = user_item['userId'].str.strip()\n",
    "    return user_item\n"
   ],
   "id": "409c795cdd7ea4c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Esse código processa múltiplos arquivos CSV contendo dados de interação do usuário, transforma-os e constrói matrizes esparsas para análise.\n",
    "\n",
    "O que ele faz? \\\n",
    "Percorre todos os arquivos CSV na pasta ../data/raw/files/treino/. \\\n",
    "Lê e transforma os dados de cada arquivo com transform_user_to_info_user_item(df). \\\n",
    "Constrói uma matriz esparsa de interação com build_interaction_matrix(df, interaction_columns). \\\n",
    "Acumula os resultados em listas (interaction_matrices e user_infos)."
   ],
   "id": "5bd2314a85a51886"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Lista para acumular as matrizes parciais\n",
    "interaction_matrices = []\n",
    "\n",
    "user_infos = []\n",
    "\n",
    "for fpath in glob.glob('../data/raw/files/treino/*.csv'):\n",
    "    print(f\"Processando: {fpath}\")\n",
    "    df = pd.read_csv(fpath)\n",
    "    df = transform_user_to_info_user_item(df)\n",
    "\n",
    "    interaction_matrices.append(build_interaction_matrix(df, interaction_columns))\n",
    "    user_infos.append(df)"
   ],
   "id": "b597c292c257d539"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "O que ele faz? \\\n",
    "Concatena todos os DataFrames de usuários (user_info). \\\n",
    "Garante um conjunto fixo de colunas para padronizar os dados (all_columns). \\\n",
    "Empilha verticalmente (vstack) as matrizes de interação geradas nos arquivos CSV. \\\n",
    "Normaliza os dados com StandardScaler para manter os valores na mesma escala. \\\n",
    "Converte novamente para uma matriz esparsa (csr_matrix), reduzindo consumo de memória. \\\n",
    "Cria categorias (Categorical) para usuários e histórico, permitindo indexação eficiente."
   ],
   "id": "8a80e749112aeba0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from scipy.sparse import vstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "\n",
    "user_info = pd.concat(user_infos, ignore_index=True)\n",
    "\n",
    "# Define um conjunto fixo de colunas baseado no DataFrame completo\n",
    "all_columns = user_infos['history'].unique()\n",
    "all_columns = pd.Index(all_columns)\n",
    "\n",
    "# Concatena todas as matrizes esparsas em uma matriz final\n",
    "if interaction_matrices:\n",
    "    print(\"Concatenando matrizes...\")\n",
    "    interaction_matrix = vstack(interaction_matrices)\n",
    "\n",
    "    # Normaliza e converte para matriz esparsa\n",
    "    print(\"Normalizando e convertendo para matriz esparsa...\")\n",
    "    interaction_matrix = StandardScaler().fit_transform(interaction_matrix.toarray())\n",
    "    interaction_matrix = csr_matrix(interaction_matrix)\n",
    "\n",
    "    # Extrai categorias de usuários e itens\n",
    "    user_id_category = pd.Categorical(range(interaction_matrix.shape[0]))\n",
    "    history_id_category = pd.Categorical(range(interaction_matrix.shape[1]))\n",
    "\n",
    "    print(\"Matriz de interação criada com sucesso!\")\n",
    "else:\n",
    "    print(\"Nenhum dado processado!\")"
   ],
   "id": "4fe64104c97e19bf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "news_item = pd.concat([pd.read_csv(fpath) for fpath in glob.glob('../data/raw/itens/itens/*.csv')])\n",
    "news_item.head()"
   ],
   "id": "868b7818cc240482"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Criando score de recencia e score de populariadade por noticia\n",
    "\n",
    "Esse código calcula dois scores para os itens de notícias:\n",
    "\n",
    "recency_score (Score de Recência)\n",
    "\n",
    "Converte a coluna issued para datetime.\n",
    "Aplica a função calc_recency_score() para calcular a recência de cada notícia.\n",
    "Normaliza os valores com MinMaxScaler() para ficarem entre 0 e 1.\n",
    "popularity_score (Score de Popularidade)\n",
    "\n",
    "Conta quantas vezes cada notícia aparece no histórico dos usuários.\n",
    "Junta essa contagem (count_visits_by_news) ao news_item.\n",
    "Renomeia a coluna pageVisitsCountHistory para popularity_score.\n",
    "Por fim, organiza os dados e exibe as primeiras linhas (head())."
   ],
   "id": "398b3c3619a6ed10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "count_visits_by_news = (user_infos\n",
    "                        .groupby('history')['pageVisitsCountHistory']\n",
    "                        .count())\n",
    "news_item['issued'] = pd.to_datetime(news_item['issued'], errors='coerce')\n",
    "news_item['recency_score'] = scaler.fit_transform(\n",
    "    news_item['issued'].apply(calc_recency_score).fillna(0).values.reshape(-1, 1)\n",
    ")\n",
    "\n",
    "\n",
    "news_item = (news_item.set_index('page').join(count_visits_by_news, how='inner').reset_index())\n",
    "news_item.rename(columns={'pageVisitsCountHistory': 'popularity_score'}, inplace=True)\n",
    "news_item.rename(columns={'index': 'history'},inplace=True)\n",
    "news_item.head()"
   ],
   "id": "bebabb3c077c2238"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "user_infos.query(\"userId == 'ec1639851d99586c7f4da928deb49187303aec6e3b8d66c0359d4920e3c105e6' and history in @filtros\")",
   "id": "f9cdd0696e9d9267"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Percebemos que o usuário não possui um vínculo forte com a notícia, ou seja, ele não expressa uma opinião clara sobre ela. Isso pode gerar desafios, pois ele pode ter visualizado a notícia sem interesse ou, por outro lado, ainda não ter visto e ter interesse em acessá-la.\n",
    "\n",
    "Diante disso, concluímos que a melhor abordagem seria utilizar... (veja o próximo notebook para descobrir!)"
   ],
   "id": "7dd1d58173441694"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
